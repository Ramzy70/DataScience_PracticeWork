{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6062,"sourceType":"datasetVersion","datasetId":3860}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-28T15:50:01.598080Z","iopub.execute_input":"2023-12-28T15:50:01.598484Z","iopub.status.idle":"2023-12-28T15:50:02.087883Z","shell.execute_reply.started":"2023-12-28T15:50:01.598451Z","shell.execute_reply":"2023-12-28T15:50:02.086400Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/movielens/movies.csv\n/kaggle/input/movielens/ratings.csv\n/kaggle/input/movielens/README.txt\n/kaggle/input/movielens/tags.csv\n/kaggle/input/movielens/links.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Load MovieLens 100k data\nfile_path = '/kaggle/input/movielens/ratings.csv'\nmovie_lens_data = pd.read_csv(file_path)\n\n# Omit the timestamp column\nratings = movie_lens_data[['userId', 'movieId', 'rating']]","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:02.090012Z","iopub.execute_input":"2023-12-28T15:50:02.090943Z","iopub.status.idle":"2023-12-28T15:50:02.846316Z","shell.execute_reply.started":"2023-12-28T15:50:02.090894Z","shell.execute_reply":"2023-12-28T15:50:02.845181Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into train and test parts (80% and 20%)\ntrain_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n\n# Display the shapes of the train and test sets\nprint(\"Train set shape:\", train_data.shape)\nprint(\"Test set shape:\", test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:02.847965Z","iopub.execute_input":"2023-12-28T15:50:02.848428Z","iopub.status.idle":"2023-12-28T15:50:04.461345Z","shell.execute_reply.started":"2023-12-28T15:50:02.848386Z","shell.execute_reply":"2023-12-28T15:50:04.460044Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Train set shape: (838860, 3)\nTest set shape: (209715, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create dense tables from train and test sets\ntraining_data = train_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\ntesting_data = test_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n\n# Display the first few rows of the training_data\nprint(\"First few rows of the training data:\")\nprint(training_data.head())","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:04.464475Z","iopub.execute_input":"2023-12-28T15:50:04.464953Z","iopub.status.idle":"2023-12-28T15:50:06.825215Z","shell.execute_reply.started":"2023-12-28T15:50:04.464920Z","shell.execute_reply":"2023-12-28T15:50:06.824018Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"First few rows of the training data:\nmovieId  1       2       3       4       5       6       7       8       \\\nuserId                                                                    \n1           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n3           4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n4           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n5           0.0     3.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\nmovieId  9       10      ...  129235  129303  129350  129354  129428  129707  \\\nuserId                   ...                                                   \n1           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n2           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n3           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n4           0.0     4.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n5           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n\nmovieId  130073  130462  130490  130642  \nuserId                                   \n1           0.0     0.0     0.0     0.0  \n2           0.0     0.0     0.0     0.0  \n3           0.0     0.0     0.0     0.0  \n4           0.0     0.0     0.0     0.0  \n5           0.0     0.0     0.0     0.0  \n\n[5 rows x 13478 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"training_data = train_data.pivot(index='userId', columns='movieId', values='rating')","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:06.826666Z","iopub.execute_input":"2023-12-28T15:50:06.827295Z","iopub.status.idle":"2023-12-28T15:50:07.765538Z","shell.execute_reply.started":"2023-12-28T15:50:06.827257Z","shell.execute_reply":"2023-12-28T15:50:07.764695Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"global_mean = training_data.stack().mean()\nprint(\"Global Mean of Ratings in the Training Data:\", global_mean)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:07.766781Z","iopub.execute_input":"2023-12-28T15:50:07.767477Z","iopub.status.idle":"2023-12-28T15:50:09.297983Z","shell.execute_reply.started":"2023-12-28T15:50:07.767443Z","shell.execute_reply":"2023-12-28T15:50:09.296663Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Global Mean of Ratings in the Training Data: 3.5285226378656747\n","output_type":"stream"}]},{"cell_type":"code","source":"users_bias = {}\nfor user_id in training_data.index:\n    user_ratings = training_data.loc[user_id].dropna()\n    sum_ratings = user_ratings.sum()\n    num_ratings = len(user_ratings)\n    bu = (sum_ratings - num_ratings * global_mean) / (0.99 + num_ratings)\n    users_bias[user_id] = bu\n\n# Display the first few entries of users' bias\nprint(\"Users' Bias:\")\nprint(list(users_bias.items())[:5])","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:09.299441Z","iopub.execute_input":"2023-12-28T15:50:09.299873Z","iopub.status.idle":"2023-12-28T15:50:11.574498Z","shell.execute_reply.started":"2023-12-28T15:50:09.299833Z","shell.execute_reply":"2023-12-28T15:50:11.573275Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Users' Bias:\n[(1, 0.19155139157958415), (2, 0.366327091149271), (3, 0.5088666277028573), (4, 0.17739993655392602), (5, 0.7702509226553298)]\n","output_type":"stream"}]},{"cell_type":"code","source":"items_bias = {}\nfor item_id in training_data.columns:\n    item_ratings = training_data[item_id].dropna()\n    sum_ratings = item_ratings.sum()\n    num_ratings = len(item_ratings)\n    bi = (sum_ratings - num_ratings * global_mean) / (0.99 + num_ratings)\n    items_bias[item_id] = bi\n\n# Display the first few entries of items' bias\nprint(\"Items' Bias:\")\nprint(list(items_bias.items())[:5])","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:11.575851Z","iopub.execute_input":"2023-12-28T15:50:11.576216Z","iopub.status.idle":"2023-12-28T15:50:16.196467Z","shell.execute_reply.started":"2023-12-28T15:50:11.576183Z","shell.execute_reply":"2023-12-28T15:50:16.195302Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Items' Bias:\n[(1, 0.4484826389628273), (2, -0.2784949032871909), (3, -0.3608503885668626), (4, -0.47228298434824195), (5, -0.42528761017005734)]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Find the indices of missing values\nmissing_indices = np.where(pd.isna(training_data))\n\n# Convert the indices to tuples\nmissing_indices = list(zip(missing_indices[0], missing_indices[1]))\n\n# Calculate the filled values using NumPy array indexing\nfilled_values = global_mean + np.array([users_bias.get(user_id, 0) + items_bias.get(item_id, 0) for user_id, item_id in missing_indices])\n\n# Replace missing values with the calculated filled values\nfor (user_id, item_id), filled_value in zip(missing_indices, filled_values):\n    filled_training_data.at[user_id, item_id] = filled_value\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:53:35.435050Z","iopub.execute_input":"2023-12-28T15:53:35.435513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Apply SVD on the training data\nU, S, V = np.linalg.svd(filled_training_data, full_matrices=False)\n\n# Display the shapes of U, S, and V\nprint(\"Shape of U:\", U.shape)\nprint(\"Shape of S:\", S.shape)\nprint(\"Shape of V:\", V.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:18.382615Z","iopub.status.idle":"2023-12-28T15:50:18.383868Z","shell.execute_reply.started":"2023-12-28T15:50:18.383609Z","shell.execute_reply":"2023-12-28T15:50:18.383641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify the desired number of columns and rows to keep\nApprox = 50  # Adjust this value based on your preference\n\n# Reduce U, S, V\nU = U[:, :Approx]\nV = V[:Approx, :]\nS = np.diag(S[:Approx])\n\n# Display the shapes of the reduced matrices\nprint(\"Shape of U (reduced):\", U.shape)\nprint(\"Shape of S (reduced):\", S.shape)\nprint(\"Shape of V (reduced):\", V.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:18.385479Z","iopub.status.idle":"2023-12-28T15:50:18.386256Z","shell.execute_reply.started":"2023-12-28T15:50:18.386006Z","shell.execute_reply":"2023-12-28T15:50:18.386028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate Z\nZ = np.dot(U, np.dot(V, S))\n\n# Display the shape of Z\nprint(\"Shape of Z:\", Z.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:18.387614Z","iopub.status.idle":"2023-12-28T15:50:18.388336Z","shell.execute_reply.started":"2023-12-28T15:50:18.388103Z","shell.execute_reply":"2023-12-28T15:50:18.388126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate MAE\nmae = np.mean(np.abs(training_array - Z))\nprint(\"Mean Absolute Error (MAE):\", mae)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:18.389584Z","iopub.status.idle":"2023-12-28T15:50:18.390291Z","shell.execute_reply.started":"2023-12-28T15:50:18.390057Z","shell.execute_reply":"2023-12-28T15:50:18.390088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.linalg import svd\nfrom sklearn.metrics import mean_absolute_error\n\n# Values of Approx to consider\napprox_values = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n\n# Dictionary to store MAE for each configuration\nmae_results = {}\n\n# Redo steps 9 to 12 for each value of Approx\nfor approx in approx_values:\n    # Reduce U, S, V\n    U_approx = U[:, :approx]\n    V_approx = V[:approx, :]\n    S_approx = np.diag(S[:approx])\n\n    # Calculate Z\n    Z_approx = U_approx @ V_approx @ S_approx\n\n    # Calculate MAE\n    mae = mean_absolute_error(training_array, Z_approx)\n    \n    # Store the MAE for the current configuration\n    mae_results[approx] = mae\n\n# Plot the bar graph\nplt.bar(mae_results.keys(), mae_results.values())\nplt.xlabel('Approx')\nplt.ylabel('MAE')\nplt.title('MAE for Different Values of Approx')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:50:18.391564Z","iopub.status.idle":"2023-12-28T15:50:18.392275Z","shell.execute_reply.started":"2023-12-28T15:50:18.392036Z","shell.execute_reply":"2023-12-28T15:50:18.392059Z"},"trusted":true},"execution_count":null,"outputs":[]}]}